trigger:
  branches:
    include:
      - main

# Link to your secret and standard variables
variables:
- group: llm-deploy-vars  # Ensure this variable group is created and includes the correct values
- name: azureSubscription
  value: 'mymlops'  # The name of your Azure Service Connection in Azure DevOps
- name: resourceGroup
  value: 'mlops'
- name: workspaceName
  value: 'llm_mlops'
- name: endpointName
  value: 'stability-endpoint'

stages:
- stage: Deploy
  jobs:
  - job: DeployModel
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    - checkout: self

    # Use Python Version 3.9 for the pipeline
    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.9'

    # Install Azure ML SDK
    - script: |
        python -m pip install --upgrade pip
        pip install azure-ai-ml azure-identity
      displayName: 'Install Azure ML SDK'

    # Deploy model to Azure ML
    - task: AzureCLI@2
      inputs:
        azureSubscription: $(azureSubscription)  # Use the Azure Service Connection from Azure DevOps
        scriptType: bash
        scriptLocation: inlineScript
        inlineScript: |
          # Login to Azure using Service Principal (this should be handled by service connection)
          az login --service-principal -u $SERVICEPRINCIPALID -p $SERVICEPRINCIPALKEY --tenant $TENANTID
          
          # Allow dynamic installation of preview extensions
          az config set extension.dynamic_install_allow_preview=true
          
          # Install the Azure ML CLI extension (if not already installed)
          az extension add --name azure-cli-ml

          # Set the correct Azure subscription using the Subscription ID
          az account set --subscription "$(AZURESUBSCRIPTIONID)"  # Use the correct Subscription ID

          # Deploy the model to Azure ML
          az ml online-endpoint create --file endpoint.yml \
            --workspace-name $WORKSPACENAME --resource-group $RESOURCEGROUP
      displayName: 'Deploy Model to Azure ML'

    # Test the deployed model endpoint
    - script: |
        # Test the deployed model endpoint by sending a request
        az ml online-endpoint invoke \
          --name $ENDPOINTNAME \
          --request-file request.json \
          --workspace-name $WORKSPACENAME \
          --resource-group $RESOURCEGROUP
      displayName: 'Test LLM Endpoint'
